{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hands-on Classification {#sec-hands-on-classification}\n",
        "\n",
        "\n",
        "\n",
        "## Describe the used dataset\n",
        "\n",
        "- Name: MNIST\n",
        "- Author: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
        "- Content: 70,000 images of digits handwritten\n",
        "- Source: [MNIST Website](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "\n",
        "## Get data\n",
        "\n",
        "### Download data\n"
      ],
      "id": "52f818bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', as_frame=False)       # as_frame=False: get data as Numpy Array instead of Pandas DataFrame\n",
        "mnist.DESCR"
      ],
      "id": "2327cd5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Look\n"
      ],
      "id": "2b2e0c9d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Size of dataset\n",
        "\n",
        "X,y = mnist.data, mnist.target\n",
        "print(X.shape, y.shape)"
      ],
      "id": "2ee2c7e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Quick look\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_digit(data):\n",
        "    image = data.reshape(28,28)\n",
        "    plt.imshow(image, cmap='binary')   # binary: grayscale color map from 0 (white) to 255 (black)\n",
        "    \n",
        "some_digit = X[0]    # Look at first digit\n",
        "plot_digit(some_digit)\n",
        "plt.show()"
      ],
      "id": "d0d32115",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create train, test set\n"
      ],
      "id": "6e5050f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Split dataset into train set and test set as its describe (train: first 60000 images, test: last 10000 images)\n",
        "\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
        "print(X_train.shape)"
      ],
      "id": "e2b77748",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Binary Classfier(5 or non-5)\n"
      ],
      "id": "607adc4d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Target labels\n",
        "\n",
        "y_train_5 = (y_train == '5')\n",
        "y_test_5 = (y_test == '5')"
      ],
      "id": "5a8010ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stochastic Gradient Descent\n",
        "\n",
        "\n",
        "#### Train model\n"
      ],
      "id": "0d095241"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)\n",
        "\n",
        "sgd_clf.predict([some_digit])"
      ],
      "id": "cf2ea695",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate model\n",
        "\n",
        "::: {.callout-tip}\n",
        "Metrics:\\\n",
        "    - Accuracy\\\n",
        "    - Confusion matrix: Precision, Recall (TPR), FPR, ROC, ROC AUC\\\n",
        "    - Plot: Precision-Recall Curve, ROC Curve\\\n",
        "Use case:\\\n",
        "    - Precision-Recall Curve: aim to care more about `false positives` than the `false negatives`\\\n",
        "    - Otherwise: ROC Curve\n",
        ":::\n",
        "\n",
        "**Accuracy**\n"
      ],
      "id": "d163f270"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
      ],
      "id": "de6f8dc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-warning}\n",
        "The accuracy scores are pretty good, but it may be due to the class imbalance. Let take a look at a Dummy Model which always classify as the most frequent class\n",
        ":::\n"
      ],
      "id": "3a4d3325"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Dummy classifier\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "dummy_model = DummyClassifier(random_state=248)\n",
        "cross_val_score(dummy_model, X_train, y_train_5, cv=3, scoring='accuracy')"
      ],
      "id": "9f47e412",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-important}\n",
        "The accuracy scores are over 90% because there's only about 10% of training set are 5 digit\\\n",
        "=> With class imbalance, accuracy score is not a useful metric\\\n",
        "=> We will use other metrics such as Precision, Recall, ROC Curve, AUC\n",
        ":::\n",
        "\n",
        "**Confusion Matrix**\n"
      ],
      "id": "c98bd793"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
        "confusion_matrix(y_train_5, y_train_pred)"
      ],
      "id": "9d4e3902",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Precision and Recall\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(f'Precision scores: {precision_score(y_train_5, y_train_pred):.4f}')\n",
        "print(f'Recall scores: {recall_score(y_train_5, y_train_pred):.4f}')"
      ],
      "id": "7ab9a528",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## F1-score\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f'F1-score: {f1_score(y_train_5, y_train_pred):.4f}')"
      ],
      "id": "8d5b8549",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Precision-Recall Trade-off**\n",
        "\n",
        "- Compute the scores of all instances in the training using *decision_function*\n",
        "- Change the threshold to see the difference\n"
      ],
      "id": "e2e4eac3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_score = sgd_clf.decision_function([some_digit])\n",
        "\n",
        "threshold = [0, 1000, 3000]\n",
        "for thr in threshold:\n",
        "    print(f'With threshold of {thr:4d}: predicted value is {y_score>thr}')"
      ],
      "id": "9f804f55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-important}\n",
        "**How to choose the suitable threshold?**\n",
        "\n",
        "- Use Precision-Recall Curve\n",
        "- precision_recall_curve: require *scores* computed from decision_function or *probabilities* from predict_proba\n",
        ":::\n"
      ],
      "id": "bb4761b0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Precision-Recall Curve\n",
        "\n",
        "\n",
        "### Compute scores by decision_function\n",
        "\n",
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, method='decision_function')\n",
        "\n",
        "### Plot Precision-Recall Curve vs Threshold\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
        "\n",
        "plt.plot(thresholds, precisions[:-1], label='Precision', color='darkslateblue')\n",
        "plt.plot(thresholds, recalls[:-1], label='Recall', color='crimson')\n",
        "plt.grid()\n",
        "plt.legend(loc='center left')\n",
        "plt.xlim([-100000,40000])\n",
        "plt.title('Precision and Recall versus Threshold')\n",
        "plt.show()"
      ],
      "id": "0bea9714",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note}\n",
        "The higher Precision, the lower Recall and vice versa\n",
        ":::\n"
      ],
      "id": "f18bbfbe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Plot Precision versus Recall\n",
        "\n",
        "plt.plot(recalls, precisions)\n",
        "plt.title('Precision versus Recall')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "id": "5d8c7247",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "Depend on your project, you would trade between precision and recall\n",
        ":::\n"
      ],
      "id": "e279d091"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Find Threshold of over 0.90 Precision\n",
        "\n",
        "idx_90_precision = (precisions >= 0.90).argmax()\n",
        "threshold_90_precision = thresholds[idx_90_precision]\n",
        "threshold_90_precision"
      ],
      "id": "2357093c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train_90_precision = (y_scores > threshold_90_precision)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(f'Accuracy score: {accuracy_score(y_train_5, y_train_90_precision):.4f}')\n",
        "print(f'Precision score: {precision_score(y_train_5, y_train_90_precision):.4f}')\n",
        "print(f'Recall score: {recall_score(y_train_5, y_train_90_precision):.4f}')\n",
        "print(f'F1 score: {f1_score(y_train_5, y_train_90_precision):.4f}')"
      ],
      "id": "d9c72297",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## ROC AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "print(f'AUC score: {roc_auc_score(y_train_5, y_scores):.4f}')       "
      ],
      "id": "b545ae5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## ROC Curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
        "idx_threshold_90_precision = (thresholds<=threshold_90_precision).argmax()      # thresholds listed decreasing => use (<=)\n",
        "fpr_90, tpr_90 = fpr[idx_threshold_90_precision], tpr[idx_threshold_90_precision]\n",
        "\n",
        "plt.plot(fpr, tpr, label='ROC Curve', color='darkslateblue')\n",
        "plt.plot([fpr_90], [tpr_90], 'o', label='Threshold for 90% precision', color='crimson')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate (Fall-out)')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.legend(loc='center right')\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "id": "081a58f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-important}\n",
        "Another trade-off: The higher TPR, the lower FPR and vice versa\n",
        ":::\n",
        "\n",
        "### Logistic Regression\n"
      ],
      "id": "281d597b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic = LogisticRegression(random_state=29)\n",
        "\n",
        "y_pred_logis = cross_val_predict(logistic, X_train, y_train_5, cv=3, method='predict_proba')[:,1]"
      ],
      "id": "ec695686",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Measure performance\n",
        "\n",
        "threshold = 0.5\n",
        "f1_logis = f1_score(y_train_5, y_pred_logis>=threshold)\n",
        "auc_logis = roc_auc_score(y_train_5, y_pred_logis>=threshold)\n",
        "\n",
        "print(f'F1 score Random Forest: {f1_logis:.4f}')\n",
        "print(f'AUC Random Forest: {auc_logis:.4f}')"
      ],
      "id": "2aa9884c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest\n"
      ],
      "id": "e7adfc73"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "y_train_pred_rf = cross_val_predict(rf_clf, X_train, y_train_5, cv=3, method='predict_proba')[:,1]"
      ],
      "id": "ca18c56c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Measure performance\n",
        "\n",
        "threshold = 0.5\n",
        "f1_rf = f1_score(y_train_5, y_train_pred_rf>=threshold)\n",
        "auc_rf = roc_auc_score(y_train_5, y_train_pred_rf>=threshold)\n",
        "\n",
        "print(f'F1 score Random Forest: {f1_rf:.4f}')\n",
        "print(f'AUC Random Forest: {auc_rf:.4f}')"
      ],
      "id": "5e1633f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## PR Curve\n",
        "\n",
        "precisions_rf, recalls_rf, thresholds_rf = precision_recall_curve(y_train_5, y_train_pred_rf)\n",
        "\n",
        "plt.plot(recalls, precisions, \"-\", label='SGD')\n",
        "plt.plot(recalls_rf, precisions_rf, label='Random Forest')\n",
        "plt.title('Precision versus Recall')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "id": "b2460887",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## ROC Curve\n",
        "\n",
        "fpr_rf, tpr_rf, thresholds = roc_curve(y_train_5, y_train_pred_rf)\n",
        "\n",
        "plt.plot(fpr, tpr, label='SGD', color='darkslateblue')\n",
        "plt.plot(fpr_rf, tpr_rf, label='Random Forest', color='crimson')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "id": "0876aa1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiclass Classification\n",
        "\n",
        "- LogisticRegression, RandomForestClassifier, GaussianNB: *natively* handle Multiclass Classification\n",
        "\n",
        "- SGDClassifier and SVC: *strictly* binary classifiers\n",
        "    - `ovo`: one versus one strategy, preferred with scale poorly algorithms (i.e. SVC)\n",
        "    - `ovr`: one versus rest strategy, preferred for almost algorithms\n",
        "\n",
        "\n",
        "### SVC\n",
        "\n",
        "#### Default: ovo strategy\n"
      ],
      "id": "92b22d46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_clf = SVC(random_state=42)\n",
        "svc_clf.fit(X_train[:1000], y_train[:1000])\n",
        "svc_clf.predict([some_digit])"
      ],
      "id": "20899b85",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Scores from decision_function\n",
        "\n",
        "some_digit_svc = svc_clf.decision_function([some_digit])\n",
        "some_digit_svc.round(4)"
      ],
      "id": "d4801269",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Class of highest score\n",
        "\n",
        "idx_svc = some_digit_svc.argmax()\n",
        "idx_svc"
      ],
      "id": "8cd5be41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Classes of prediction\n",
        "svc_clf.classes_[idx_svc]"
      ],
      "id": "a9fdd19b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Force: ovr strategy\n"
      ],
      "id": "01327f8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Train model\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "ovr_svc_clf = OneVsRestClassifier(SVC(random_state=42))\n",
        "ovr_svc_clf.fit(X[:1000], y_train[:1000])\n",
        "ovr_svc_clf.predict([some_digit])"
      ],
      "id": "730c7740",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Compute scores\n",
        "\n",
        "some_digit_ovr_svc = ovr_svc_clf.decision_function([some_digit])\n",
        "some_digit_ovr_svc.round(4)"
      ],
      "id": "36d0c5dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Class of hishest score\n",
        "\n",
        "some_digit_ovr_svc.argmax()"
      ],
      "id": "dc966e1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Extract classes\n",
        "\n",
        "ovr_svc_clf.classes_"
      ],
      "id": "9e55faa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SGD\n"
      ],
      "id": "0e09a8df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Train model\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "sgd_clf.predict([some_digit])"
      ],
      "id": "622ef030",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's incorrect. As we can see,The Classifier is not very confident about its prediction. \n"
      ],
      "id": "fbfdbafd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Compute scores\n",
        "\n",
        "sgd_clf.decision_function([some_digit])"
      ],
      "id": "46ae83a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use cross validation to evaluate our model\n"
      ],
      "id": "0109e2b0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')"
      ],
      "id": "73b25443",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can scale the data to get better result\n"
      ],
      "id": "becdfc9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype('float64'))\n",
        "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring='accuracy')"
      ],
      "id": "9d47a526",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the confusion matrix of our prediction\n"
      ],
      "id": "6f62acaf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Predict using cross_val_predict\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)"
      ],
      "id": "15eec3b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confusion matrix with (right) and without (left) normalization.\n"
      ],
      "id": "d24498e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(9, 4))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=ax[0])\n",
        "ax[0].set_title(\"Confusion matrix\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=ax[1], normalize='true', values_format='.0%')\n",
        "ax[1].set_title(\"CM normalized by row\")\n",
        "\n",
        "plt.show()"
      ],
      "id": "5d7b3f2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In row #5 and column #8 on the left plot, it's means 10% of true 5s is misclassified as 8s. Kinda hard to see the errors made by model. Therefore, we will put 0 weight on correct prediction (error plot).\n",
        "\n",
        "Confustion matrix with error normalized by row (left) and by column (right) (normalize=['true','pred'])\n"
      ],
      "id": "08d663d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(9, 4))\n",
        "\n",
        "sample_weight = (y_train != y_train_pred)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=ax[0],sample_weight=sample_weight, normalize='true', values_format='.0%')\n",
        "ax[0].set_title(\"Confusion matrix\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=ax[1],sample_weight=sample_weight, normalize='pred', values_format='.0%')\n",
        "ax[1].set_title(\"CM normalized by row\")\n",
        "\n",
        "plt.show()"
      ],
      "id": "bd4e78f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In row #5 and column #8 on the left plot, it's means 55% of errors made on true 5s is misclassified as 8s.\n",
        "\n",
        "In row #5 and column #8 on the right plot, it's means 19% of misclassified 8s are actually 5s.\n",
        "\n",
        "Analyzing the made errors can help us gain insights and why the classifier failing\n",
        "\n",
        "\n",
        "\n",
        "## Multilabel Classification\n",
        "\n",
        "Output is multilabel for each instances. For example, we will classify whether the digit is large (>7) and is odd\n",
        "\n",
        "### K Nearest Neighbors\n"
      ],
      "id": "25db7eeb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Train model\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "y_train_large = (y_train >= '7')\n",
        "y_train_odd = (y_train.astype('int8') % 2 == 1)\n",
        "y_train_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_scaled, y_train_multilabel)\n",
        "knn.predict([some_digit])"
      ],
      "id": "a5d260b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute average F1 score across all labels (equally important)\n"
      ],
      "id": "583c8f44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Evaluate model\n",
        "\n",
        "y_train_pred_knn = cross_val_predict(knn, X_train_scaled, y_train, cv=3)\n",
        "f1_score(y_train, y_train_pred_knn, average='macro')"
      ],
      "id": "873f7436",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another approach is to give each label a weight equal to its number of instances\n"
      ],
      "id": "fe33819e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "f1_score(y_train, y_train_pred_knn, average='weighted')"
      ],
      "id": "2b2597c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVC\n",
        "\n",
        "- SVC does not natively support multilabel classification. Therefore, there are 2 strategies:\n",
        "1. Train one model per label. It turns out that it's hard to capture the dependencies between labels\n",
        "2. Train models sequentially (ChainClassifier): using input features and all predictions of previous models in the chain\n"
      ],
      "id": "9856963f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.multioutput import ClassifierChain\n",
        "\n",
        "chain_clf = ClassifierChain(SVC(), cv=3, random_state=42)\n",
        "chain_clf.fit(X_train_scaled[:2000], y_train_multilabel[:2000])\n",
        "chain_clf.predict([some_digit])"
      ],
      "id": "ff69355d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multioutput Classification\n",
        "\n",
        "- Multiclass-multilabel classification\n",
        "- For example, we will build a model that removes noise from an digit image\n",
        "- Output is a clean image 28x28: multilabel (one label per pixel) and multiclass (pixel intensity range from 0-255 per label)\n"
      ],
      "id": "b5ab0751"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Create a noisy train set\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = np.random.randint(0,100,(len(X_train), 28*28))\n",
        "X_train_noise = X_train + noise\n",
        "y_train_noise = X_train\n",
        "\n",
        "noise = np.random.randint(0,100,(len(X_test), 28*28))\n",
        "X_test_noise = X_test + noise\n",
        "y_test_noise = X_test"
      ],
      "id": "80ce6493",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at sample images\n"
      ],
      "id": "147e337b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.subplot(1,2,1)\n",
        "plot_digit(X_train_noise[0])\n",
        "plt.subplot(1,2,2)\n",
        "plot_digit(y_train_noise[0])\n",
        "\n",
        "plt.show()"
      ],
      "id": "36d7493c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "knn.fit(X_train_noise, y_train_noise)\n",
        "y_pred_noise = knn.predict([X_train_noise[0]])\n",
        "plot_digit(y_pred_noise)"
      ],
      "id": "88f864d9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "dhuy",
      "language": "python",
      "display_name": "dhuy"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}