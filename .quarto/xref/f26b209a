{"headings":["linear-svm-classification-support-vector-classification---svc","sec-nonlinear-svm","svms-classes-computational-complexity","svm-regression-support-vector-regression---svr","understand-the-fundamentals-of-svm","quadratic-programming-problem-qp-solver","gradient-descent","kernelized-svms","sec-svm"],"entries":[{"order":{"number":1,"section":[8,0,0,0,0,0,0]},"key":"sec-svm"},{"order":{"number":3,"section":[8,1,0,0,0,0,0]},"key":"fig-parameter-c","caption":"Different C parameters"},{"order":{"number":11,"section":[8,5,3,0,0,0,0]},"key":"fig-common-kernels","caption":"Common kernels"},{"order":{"number":8,"section":[8,5,0,0,0,0,0]},"key":"fig-small-weigths","caption":"A smaller weights results in a larger margin"},{"order":{"number":4,"section":[8,2,0,0,0,0,0]},"key":"fig-nonlinearly-seperable","caption":"Non-linearly seperable"},{"order":{"number":1,"section":[8,2,0,0,0,0,0]},"key":"sec-nonlinear-svm","caption":"8.2 Non-linear SVM Classification"},{"order":{"number":1,"section":[8,1,0,0,0,0,0]},"key":"fig-svm","caption":"Large margin classification"},{"order":{"number":10,"section":[8,5,3,0,0,0,0]},"key":"fig-kernel-trick","caption":"Kernel trick for a second-degree polynomial"},{"order":{"number":2,"section":[8,1,0,0,0,0,0]},"key":"fig-feature-scaling","caption":"SVMs are sensitive to feature scaling"},{"order":{"number":6,"section":[8,3,0,0,0,0,0]},"key":"fig-svm-bigO","caption":"BigO of SVM classification"},{"order":{"number":5,"section":[8,2,0,0,0,0,0]},"key":"fig-c-gamma","caption":"Different C and gamma parameters"},{"order":{"number":7,"section":[8,4,0,0,0,0,0]},"key":"fig-different-epsilon","caption":"Different epsilons"},{"order":{"number":9,"section":[8,5,2,0,0,0,0]},"key":"fig-hinge-loss","caption":"The hinge loss and squared hinge loss"}],"options":{"chapters":true,"chapter-id":"sec-svm"}}